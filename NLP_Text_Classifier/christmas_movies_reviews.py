# -*- coding: utf-8 -*-
"""Christmas_Movies_Reviews.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FhM3FpUcPbsFMeS_5lS7jxRhvElxEQD7

## Installing and Importing Necessary Libraries
"""

# Installation for GPU llama-cpp-python
!CMAKE_ARGS="-DLLAMA_CUBLAS=on" FORCE_CMAKE=1 pip install llama-cpp-python --force-reinstall --upgrade --no-cache-dir -q

# For downloading the models from HF Hub
!pip install huggingface_hub -q

# Importing library for data manipulation
import pandas as pd

# Function to download the model from the Hugging Face model hub
from huggingface_hub import hf_hub_download

# Importing the Llama class from the llama_cpp module
from llama_cpp import Llama

# Importing the json module
import json

"""## Import the dataset"""

from google.colab import drive
drive.mount('/content/drive')

data = pd.read_csv("/content/drive/MyDrive/Previous_Projects/christmas_movies_reviews.csv")
df = data.sample(frac = 1)

"""## Data Overview"""

# checking the first five rows of the data
df.head()

# checking the shape of the data
df.shape

"""**Observations**

- Data has 20 rows and 3 columns
"""

# checking for missing values
df.isnull().sum()

"""**Observations**

- There are no missing values in the data

## Model Building

### Loading the model
"""

model_name_or_path = "TheBloke/Llama-2-13B-chat-GGUF"
model_basename = "llama-2-13b-chat.Q5_K_M.gguf" # the model is in gguf format

# Using hf_hub_download to download a model from the Hugging Face model hub
# The repo_id parameter specifies the model name or path in the Hugging Face repository
# The filename parameter specifies the name of the file to download
model_path = hf_hub_download(
    repo_id=model_name_or_path,
    filename=model_basename
)

lcpp_llm = Llama(
    model_path=model_path,
    n_threads=2,  # CPU cores
    n_batch=512,  # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.
    n_gpu_layers=50,  # Change this value based on your model and your GPU VRAM pool.
    n_ctx=4200,  # Context window
)

"""### Defining Model Response Parameters"""

def generate_llama_response(instruction, review):

    # System message explicitly instructing not to include the review text
    system_message = """
        [INST]<<SYS>>
        {}
        <</SYS>>[/INST]
    """.format(instruction)

    # Combine user_prompt and system_message to create the prompt
    prompt = f"{review}\n{system_message}"

    # Generate a response from the LLaMA model
    response = lcpp_llm(
        prompt=prompt,
        max_tokens=1024,
        temperature=0,
        top_p=0.95,
        repeat_penalty=1.0,
        top_k=50,
        stop=['INST'],
        echo=False,
        seed=42,
    )

    # Extract the sentiment from the response
    response_text = response["choices"][0]["text"]
    return response_text

"""## 1. Sentiment Analysis"""

# creating a copy of the data
df2 = df.copy()

# defining the instructions for the model
instruction_A = """
    You are an expert at analyzing christmas reviews. Classify the sentiment of the provided review into the following categories:
    - Positive
    - Negative
    - Neutral
"""

df2['llama_response'] = df2['Review'].apply(lambda x: generate_llama_response(instruction_A, x))

df2['llama_response'].head()

i = 5
print(df2.loc[i, 'llama_response'])

print(df2.loc[i, 'llama_response'])

def sentiment_extractor(llama_response):
    if 'positive' in llama_response.lower():
        return 'Positive'
    elif 'negative' in llama_response.lower():
        return 'Negative'
    elif 'neutral' in llama_response.lower():
        return 'Neutral'

# applying the function to the model response
df2['sentiment'] = df2['llama_response'].apply(sentiment_extractor)
df2['sentiment'].head()

df2['sentiment'].value_counts()

"""####**filter for rows with negative and neutral opinion**"""

df2[(df2['sentiment'] != 'Positive')]

"""## 2. Sentiment Analysis and Returning Structured Output"""

# creating a copy of the data
df3 = df.copy()

# defining the instructions for the model
instruction_B = """
    You are an expert at analyzing christmas reviews. Classify the sentiment of the provided review into the following categories:
    - Positive
    - Negative
    - Neutral

    Format the output as a JSON object with a single key-value pair as shown below:
    {"sentiment": "your_sentiment_prediction"}
"""

df3['llama_response'] = df3['Review'].apply(lambda x: generate_llama_response(instruction_B, x))

df3['llama_response'].head()

i = 5
print(df3.loc[i, 'Review'])

# defining a function to parse the JSON output from the model
def json_extractor(json_str):
    try:
        # Find the indices of the opening and closing curly braces
        json_start = json_str.find('{')
        json_end = json_str.rfind('}')

        if json_start != -1 and json_end != -1:
            extracted_sentiment = json_str[json_start:json_end + 1]  # Extract the JSON object
            data_dict = json.loads(extracted_sentiment)
            return data_dict
        else:
            print(f"Warning: JSON object not found in response: {json_str}")
            return {}
    except json.JSONDecodeError as e:
        print(f"Error parsing JSON: {e}")
        return {}

# applying the function to the model response
df3['llama_response_parsed'] = df3['llama_response'].apply(json_extractor)
df3['llama_response_parsed'].head()

llama_response_parsed_df3 = pd.json_normalize(df3['llama_response_parsed'])
llama_response_parsed_df3.head()

data_with_parsed_llama_output_3 = pd.concat([df3, llama_response_parsed_df3], axis=1)
data_with_parsed_llama_output_3.head()

final_data_3 = data_with_parsed_llama_output_3.drop(['llama_response_parsed'], axis=1)
final_data_3.head()

final_data_3['sentiment'].value_counts(normalize = True)

"""## 3. Identifying Overall Sentiment and Sentiment of Aspects of the Experience"""

# creating a copy of the data
df4 = data.copy()

# defining the instructions for the model
instruction_C = """
    You are an expert at analyzing christmas reviews. Classify the overall sentiment of the provided review into the following categories:
    - "Positive"
    - "Negative"
    - "Neutral"

    Once that is done, check for a mention of the following aspects in the review and classify the sentiment of each aspect as "Positive", "Negative", or "Neutral":
    1. "Plot"
    2. "Duration"
    3. "Cast"

    Output the overall sentiment and sentiment for each category in a JSON format with the following keys:
    {
        "Overall": "your_sentiment_prediction",
        "Plot": "your_sentiment_prediction",
        "Duration": "your_sentiment_prediction",
        "Cast": "your_sentiment_prediction"
    }

    In case one of the three aspects is not mentioned in the review, set "Not Applicable" (including quotes) for the corresponding JSON key value.
    Only return the JSON, do not return any other information.
"""

df4['llama_response'] = df4['Review'].apply(lambda x: generate_llama_response(instruction_C, x))

df4['llama_response'].head()

i = 5
print(df4.loc[i, 'Review'])

print(df4.loc[i, 'llama_response'])

# applying the function to the model response
df4['llama_response_parsed'] = df4['llama_response'].apply(json_extractor)
df4['llama_response_parsed'].head()

llama_response_parsed_df_4 = pd.json_normalize(df4['llama_response_parsed'])
llama_response_parsed_df_4.head()

data_with_parsed_llama_output_4 = pd.concat([df4, llama_response_parsed_df_4], axis=1)
data_with_parsed_llama_output_4.head()

final_data_4 = data_with_parsed_llama_output_4.drop(['llama_response','llama_response_parsed'], axis=1)
final_data_4.head()

final_data_4['Overall'].value_counts(normalize = True)

final_data_4['Plot'].value_counts()

final_data_4['Duration'].value_counts()

final_data_4['Cast'].value_counts()

"""## 4. Identifying Overall Sentiment, Sentiment of Aspects of the Experience, and the Liked/Disliked Features of the Different Aspects of the Experience"""

# creating a copy of the data
df5 = data.copy()

# defining the instructions for the model
instruction_D = """
     You are an expert at analyzing christmas reviews. Your goal is to classify the overall sentiment of the provided review into the following categories:
        - Positive
        - Negative
        - Neutral

    Subsequently, assess the sentiment of specific aspects mentioned in the review, namely:
        1. Plot
        2. Duration
        3. Cast

    Further, identify liked and/or disliked features associated with each aspect in the review.

    Return the output in the specified JSON format, ensuring consistency and handling missing values appropriately:

    {
        "Overall": "your_sentiment_prediction",
        "Plot": "your_sentiment_prediction",
        "Duration": "your_sentiment_prediction",
        "Cast": "your_sentiment_prediction",
        "Plot Features": ["liked/disliked features"],
        "Duration Features": ["liked/disliked features"],
        "Cast Features": ["liked/disliked features"]
    }

    The sentiment prediction for Overall, Plot, Duration, and Cast should be one of "Positive", "Negative", or "Neutral" only.
    In case one of the three aspects is not mentioned in the review, set "Not Applicable" (including quotes) in the corresponding JSON key value for the sentiment.
    In case there are no liked/disliked features for a particular aspect, assign an empty list in the corresponding JSON key value for the aspect.
    Only return the JSON, do NOT return any other text or information.
"""

df5['llama_response'] = df5['Review'].apply(lambda x: generate_llama_response(instruction_D, x).replace('\n', ''))

i = 5
print(df5.loc[i, 'Review'])

print(df5.loc[i, 'llama_response'])

# applying the function to the model response
df5['llama_response_parsed'] = df5['llama_response'].apply(json_extractor)
df5['llama_response_parsed'].head()

df5[df5.llama_response_parsed == {}]

"""- There are three model responses that the JSON parser function could not parse
- We'll manually add the values for these three responses
"""

print(df5.loc[5, 'llama_response'])

print(df5.loc[9, 'llama_response'])

print(df5.loc[10, 'llama_response'])

"""**Note**: The values model responses that cannot be parsed correctly by the JSON parser function may vary with execution due to the randomness associated with LLMs. Kindly update as observed when run in your system."""

llama_response_parsed_df_5 = pd.json_normalize(df5['llama_response_parsed'])
llama_response_parsed_df_5.head()

data_with_parsed_model_output_5 = pd.concat([df5, llama_response_parsed_df_5], axis=1)
data_with_parsed_model_output_5.head()

final_data_5 = data_with_parsed_model_output_5.drop(['llama_response','llama_response_parsed'], axis=1)
final_data_5.head()

final_data_5['Overall'].value_counts(normalize = True)

final_data_5['Plot Features'].value_counts(normalize = False)

final_data_4['Duration'].value_counts()

final_data_4['Cast'].value_counts()

"""## 5. Identifying Overall Sentiment, Sentiment of Aspects of the Experience, Liked/Disliked Features of the Different Aspects of the Movie, and Sharing a Response"""

# creating a copy of the data
df6 = df.copy()

# defining the instructions for the model
instruction_E = """
    You are an expert at analyzing christmas reviews. Classify the overall sentiment of the provided review into the following categories:
    - "Positive"
    - "Negative"
    - "Neutral"

    Once that is done, check for a mention of the following aspects in the review and clasify the sentiment of each aspect as positive, negative, or neutral:
    1. Plot
    2. Duration
    3. Cast

    Once that is done, look for liked and/or disliked features mentioned against each of the above aspects in the review and extract them.

    Finally, draft a response for the reviewer based on the review. Start out with an appreciation text and then add on to it as per the following:
    1. If the review is positive, mention that the next sequel
    2. If the review is neutral, ask them for what could have been done to improve their cinematography experience
    3. If the review is negative, let them know that feedback will be reviewed and incorporated in the sequel

    Return the output in the specified JSON format, ensuring consistency and handling missing values appropriately Ensure that all values in the JSON are formatted as strings, and each element within the lists should be enclosed in double quotes:

    {
        "Overall": "your_sentiment_prediction",
        "Plot": "your_sentiment_prediction",
        "Duration": "your_sentiment_prediction",
        "Cast": "your_sentiment_prediction",
        "Plot Features": ["liked/disliked features"],
        "Duration Features": ["liked/disliked features"],
        "Cast Features": ["liked/disliked features"],
        "Response": "your_response_to_the_customer_review",
    }

    The sentiment prediction for Overall, Plot, Duration, and Cast should be one of "Positive", "Negative", or "Neutral" only.
    In case one of the three aspects is not mentioned in the review, set "Not Applicable" (including quotes) in the corresponding JSON key value for the sentiment.
    In case there are no liked/disliked features for a particular aspect, assign an empty list in the corresponding JSON key value for the aspect.
    Be polite and empathetic in the response to the customer review.
    Only return the JSON, do NOT return any other text or information.
"""

df6['llama_response'] = df6['Review'].apply(lambda x: generate_llama_response(instruction_E, x))

i = 5
print(df6.loc[i, 'Review'])

print(df6.loc[i, 'llama_response'])

# applying the function to the model response
df6['llama_response_parsed'] = df6['llama_response'].apply(json_extractor)
df6['llama_response_parsed'].head()

llama_response_parsed_df_6 = pd.json_normalize(df6['llama_response_parsed'])
llama_response_parsed_df_6.head()

data_with_parsed_model_output_6 = pd.concat([df6, llama_response_parsed_df_6], axis=1)
data_with_parsed_model_output_6.head()

final_df6 = data_with_parsed_model_output_6.drop(['llama_response','llama_response_parsed'], axis=1)
final_df6.head()

final_df6['Overall'].value_counts()

final_df6['Plot'].value_counts()

final_df6['Duration'].value_counts()

final_df6['Cast'].value_counts()

"""## Conclusions

- for model optimization, we can explore the following to improve performance:
    1. finetune the prompt
    2. Update the model parameters (`temparature`, `top_p`, `top_k`, `max_toxen`)

___
"""